{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fde367d4",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca7ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns ; sns.set()\n",
    "\n",
    "# For Text Preprocessing\n",
    "import re\n",
    "\n",
    "# For Splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# For Imputing missing values\n",
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56679479",
   "metadata": {},
   "source": [
    "# Define classes & functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa53e7c",
   "metadata": {},
   "source": [
    "## Cleaning Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667ce3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_price(df):\n",
    "    dropped_data = df[(df.price < 1000) | (df.price > 70000)].index\n",
    "    df.drop(dropped_data, axis = 0, inplace = True)\n",
    "    \n",
    "    print('\\tPrice filtered\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ca1b05",
   "metadata": {},
   "source": [
    "## Cleaning odometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a53c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_odometer(df):\n",
    "    dropped_data = df[df.odometer >= 1000000].index\n",
    "    df.drop(dropped_data, axis = 0, inplace = True)\n",
    "    \n",
    "    print('\\tOdometer filtered\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a6e42b",
   "metadata": {},
   "source": [
    "## Encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cf9a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cylinders(df):\n",
    "    df['cylinders'] = [float(d) for d in df.cylinders.str.extract(r'(\\d+)')[0]]\n",
    "    \n",
    "    print('\\t\"Cylinders\" encoded\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da15f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_condition(df):\n",
    "    condition_dict = {'salvage':0,\n",
    "                     'fair':1,\n",
    "                     'good':2,\n",
    "                     'excellent':3,\n",
    "                     'like new':4,\n",
    "                     'new':5}\n",
    "\n",
    "    df['condition'].replace(condition_dict, inplace = True)\n",
    "    \n",
    "    print('\\t\"Condition\" encoded\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "509f12da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_fuel(df):\n",
    "    fuel_dict = {'gas':1,\n",
    "                'other':0,\n",
    "                'diesel':0,\n",
    "                'hybrid':0,\n",
    "                'electric':0}\n",
    "\n",
    "    df['fuel'].replace(fuel_dict, inplace = True)\n",
    "    df.rename(columns = {'fuel':'fuel_gas'}, inplace = True)\n",
    "    \n",
    "    print('\\t\"Fuel\" encoded\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee741b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_title_status(df):\n",
    "    title_status_dict = {'clean':1,\n",
    "                'rebuilt':1,\n",
    "                'salvage':0,\n",
    "                'lien':0,\n",
    "                'missing':0,\n",
    "                'parts only':0}\n",
    "\n",
    "    df['title_status'].replace(title_status_dict, inplace = True)\n",
    "    df.rename(columns = {'title_status':'title_status_ok'}, inplace = True)\n",
    "    \n",
    "    print('\\t\"Title status\" encoded\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae921fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_transmission(df):\n",
    "    transmission_dict = {'automatic':1,\n",
    "                        'other':0,\n",
    "                        'manual':0}\n",
    "    \n",
    "    df['transmission'].replace(transmission_dict, inplace = True)\n",
    "    df.rename(columns = {'transmission':'transmission_automatic'}, inplace = True)\n",
    "    \n",
    "    print('\\t\"Transmission\" encoded\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d18e6673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_type(df):\n",
    "    top_4_type = df.type.value_counts()[:4].index\n",
    "    \n",
    "    df.type = ['other' if car_type not in top_4_type else car_type for car_type in df.type] \n",
    "    \n",
    "    print('\\tType encoded\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcc9b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_paint_color(df):\n",
    "    d = {'silver':'grey'}\n",
    "    df.paint_color.replace(d, inplace = True)\n",
    "    \n",
    "    top_4_colors = ['white', 'grey', 'black', 'blue']\n",
    "    \n",
    "    df.paint_color = ['other' if color not in top_4_colors else color for color in df.paint_color]\n",
    "    \n",
    "    print('\\tPaint color encoded\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12edc86",
   "metadata": {},
   "source": [
    "## Feature Engineering with External/Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff698483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def states_to_regions(df, states_data):\n",
    "    states_data['State Code'] = [code.lower() for code in states_data['State Code']]\n",
    "    \n",
    "    region_values = states_data['Region'].values\n",
    "    state_code = states_data['State Code']\n",
    "\n",
    "    d_regions = dict(zip(state_code, region_values))\n",
    "    \n",
    "    df.state.replace(d_regions, inplace = True)\n",
    "    df.rename(columns = {'state':'regions_usa'}, inplace = True)\n",
    "    \n",
    "    print('\\tStates data encoded into Regions\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5309c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manufacturers_origin(df, manufacturers_data):\n",
    "    # Change some compounds name on dataset\n",
    "    d_mod = {}\n",
    "    for brand in set(df.manufacturer):\n",
    "        if type(brand) == str:\n",
    "            if ('-' in brand) and (brand != 'mercedes-benz'):\n",
    "                d_mod[brand] = re.sub('-',' ',brand)\n",
    "    \n",
    "    df.manufacturer.replace(d_mod, inplace = True)\n",
    "    \n",
    "    # Create dictionary \"manufacturer - continent\"\n",
    "    dict_cars_origin = {}\n",
    "\n",
    "    for brand in set(df.manufacturer):\n",
    "        if len(manufacturers_data[manufacturers_data.isin([f'{brand}'])].stack()) > 0:\n",
    "            dict_cars_origin[f'{brand}'] = manufacturers_data[manufacturers_data.isin([f'{brand}'])].stack().index[0][1]\n",
    "    \n",
    "    # Adding missing brands\n",
    "    dict_cars_origin['saturn'] = 'north america '\n",
    "    dict_cars_origin['rover'] = 'europe '\n",
    "    dict_cars_origin['pontiac'] = 'north america '\n",
    "    dict_cars_origin['mercury'] = 'north america '\n",
    "    dict_cars_origin['harley davidson'] = 'north america '\n",
    "    \n",
    "    # Replacing manufacturers\n",
    "    df.manufacturer = df.manufacturer.replace(dict_cars_origin)\n",
    "    \n",
    "    print('\\tManufacturer data regrouped by manufacturer origin (continent)\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b8f58a",
   "metadata": {},
   "source": [
    "## Defining functions to apply fit/transform methods from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c429fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_imputer(train_set, test_set):\n",
    "    # Filter rows with too many missing values\n",
    "    train_rows_to_drop = train_set[train_set.isnull().sum(axis = 1) > 4].index\n",
    "    test_rows_to_drop = test_set[test_set.isnull().sum(axis = 1) > 4].index\n",
    "    \n",
    "    train_set.drop(train_rows_to_drop, axis = 0, inplace = True)\n",
    "    test_set.drop(test_rows_to_drop, axis = 0, inplace = True)\n",
    "    \n",
    "    train_set.reset_index(inplace = True, drop = True)\n",
    "    test_set.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    # One-Hot encode categorical features\n",
    "    train_set = pd.get_dummies(train_set)\n",
    "    test_set = pd.get_dummies(test_set)\n",
    "    \n",
    "    \n",
    "    dummies_to_drop = ['manufacturer_europe ', 'drive_4wd', 'type_other', 'paint_color_other', 'regions_usa_Northeast']\n",
    "    \n",
    "    train_set.drop(dummies_to_drop, axis = 1, inplace = True)\n",
    "    test_set.drop(dummies_to_drop, axis = 1, inplace = True)\n",
    "        \n",
    "        \n",
    "    # Apply imputer\n",
    "    imp = IterativeImputer(random_state = 42, skip_complete = True,\n",
    "                      min_value = [train_set.iloc[:, i].min() for i in range(len(train_set.columns))],\n",
    "                      max_value = [train_set.iloc[:, i].max() for i in range(len(train_set.columns))])\n",
    "    \n",
    "    imp.fit(train_set)\n",
    "    \n",
    "    train = imp.transform(train_set)\n",
    "    test = imp.transform(test_set)\n",
    "    \n",
    "    train_set = pd.DataFrame(train, columns = train_set.columns)\n",
    "    test_set = pd.DataFrame(test, columns = test_set.columns)\n",
    "    \n",
    "    print('Missing data handled with Iterative Imputer')\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "090036ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_robust_feature_scaling(train_set, test_set):\n",
    "    X_train, X_test = train_set.iloc[:, 1:].values, test_set.iloc[:, 1:].values\n",
    "    y_train, y_test = train_set.iloc[:, 0].values,  test_set.iloc[:, 0].values\n",
    "    \n",
    "    rsc = RobustScaler()\n",
    "    rsc.fit(X_train)\n",
    "    X_train_ = rsc.transform(X_train)\n",
    "    X_test_ = rsc.transform(X_test)\n",
    "    \n",
    "    y_train_ = y_train.reshape(len(train_set),1)\n",
    "    y_test_ = y_test.reshape(len(test_set),1)\n",
    "    \n",
    "    scaled_train_data = np.concatenate((y_train_, X_train_), axis = 1)\n",
    "    scaled_test_data = np.concatenate((y_test_, X_test_), axis = 1)\n",
    "\n",
    "    header = list(train_set.columns)\n",
    "   \n",
    "    train_set_std = pd.DataFrame(scaled_train_data, columns = header)\n",
    "    test_set_std = pd.DataFrame(scaled_test_data, columns = header)\n",
    "    \n",
    "    print('Data standardized')\n",
    "    \n",
    "    return train_set_std, test_set_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcce1f3e",
   "metadata": {},
   "source": [
    "# Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09b9ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipeline(df, states_data, manufacturers_data):\n",
    "    \n",
    "    functions  = [filter_price,\n",
    "                        filter_odometer,\n",
    "                        encode_cylinders,\n",
    "                        encode_condition,\n",
    "                        encode_fuel,\n",
    "                        encode_title_status,\n",
    "                        encode_transmission,\n",
    "                        encode_type,\n",
    "                        encode_paint_color,\n",
    "                        states_to_regions, \n",
    "                        manufacturers_origin]\n",
    "    \n",
    "    sp_functions = [states_to_regions, manufacturers_origin]\n",
    "    \n",
    "    for func in functions:\n",
    "        print(f'Function being applied: \"{func.__name__}\"')\n",
    "        if func not in sp_functions:\n",
    "            df = func(df)\n",
    "        elif func == states_to_regions:\n",
    "            df = func(df, states_data)\n",
    "        elif func == manufacturers_origin:\n",
    "            df = func(df, manufacturers_data)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc300b",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "032313dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('vehicles.csv')\n",
    "df_regions = pd.read_csv('states.csv')\n",
    "df_car_origin = pd.read_csv('scraped_car_origin.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5da974d",
   "metadata": {},
   "source": [
    "## Remove Unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8af6a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['id', 'url', 'region_url', 'VIN', 'image_url', 'description',\n",
    "                    'posting_date', 'region', 'lat', 'long', 'county', 'size', 'model']\n",
    "\n",
    "data = raw_data.drop(features_to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32a688a",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76c8a6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(341504, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, test_set = train_test_split(data, test_size = 0.2, random_state = 42) \n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62bb93d",
   "metadata": {},
   "source": [
    "# Apply main preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92874c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function being applied: \"filter_price\"\n",
      "\tPrice filtered\n",
      "\n",
      "Function being applied: \"filter_odometer\"\n",
      "\tOdometer filtered\n",
      "\n",
      "Function being applied: \"encode_cylinders\"\n",
      "\t\"Cylinders\" encoded\n",
      "\n",
      "Function being applied: \"encode_condition\"\n",
      "\t\"Condition\" encoded\n",
      "\n",
      "Function being applied: \"encode_fuel\"\n",
      "\t\"Fuel\" encoded\n",
      "\n",
      "Function being applied: \"encode_title_status\"\n",
      "\t\"Title status\" encoded\n",
      "\n",
      "Function being applied: \"encode_transmission\"\n",
      "\t\"Transmission\" encoded\n",
      "\n",
      "Function being applied: \"encode_type\"\n",
      "\tType encoded\n",
      "\n",
      "Function being applied: \"encode_paint_color\"\n",
      "\tPaint color encoded\n",
      "\n",
      "Function being applied: \"states_to_regions\"\n",
      "\tStates data encoded into Regions\n",
      "\n",
      "Function being applied: \"manufacturers_origin\"\n",
      "\tManufacturer data regrouped by manufacturer origin (continent)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set = preprocessing_pipeline(train_set, df_regions, df_car_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42b9f42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function being applied: \"filter_price\"\n",
      "\tPrice filtered\n",
      "\n",
      "Function being applied: \"filter_odometer\"\n",
      "\tOdometer filtered\n",
      "\n",
      "Function being applied: \"encode_cylinders\"\n",
      "\t\"Cylinders\" encoded\n",
      "\n",
      "Function being applied: \"encode_condition\"\n",
      "\t\"Condition\" encoded\n",
      "\n",
      "Function being applied: \"encode_fuel\"\n",
      "\t\"Fuel\" encoded\n",
      "\n",
      "Function being applied: \"encode_title_status\"\n",
      "\t\"Title status\" encoded\n",
      "\n",
      "Function being applied: \"encode_transmission\"\n",
      "\t\"Transmission\" encoded\n",
      "\n",
      "Function being applied: \"encode_type\"\n",
      "\tType encoded\n",
      "\n",
      "Function being applied: \"encode_paint_color\"\n",
      "\tPaint color encoded\n",
      "\n",
      "Function being applied: \"states_to_regions\"\n",
      "\tStates data encoded into Regions\n",
      "\n",
      "Function being applied: \"manufacturers_origin\"\n",
      "\tManufacturer data regrouped by manufacturer origin (continent)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set = preprocessing_pipeline(test_set, df_regions, df_car_origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f9fdc9",
   "metadata": {},
   "source": [
    "## Applying imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "529347c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data handled with Iterative Imputer\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = apply_imputer(train_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64944fa",
   "metadata": {},
   "source": [
    "## Applying feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73b73ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data standardized\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = apply_robust_feature_scaling(train_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9801536",
   "metadata": {},
   "source": [
    "# Exporting preprocessed sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44e9d4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set shape = (300999, 23),  contains 80% of total data \n",
      "test_set shape  =  (75366, 23),  contains 20% of total data\n"
     ]
    }
   ],
   "source": [
    "# Check results\n",
    "tot = len(train_set) + len(test_set)\n",
    "\n",
    "print(f'train_set shape = {train_set.shape},  contains {round(len(train_set) / tot * 100)}% of total data \\n' \n",
    "      f'test_set shape  =  {test_set.shape},  contains {round(len(test_set) / tot * 100)}% of total data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c71530e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv('train_set_preprocessed.csv', index = False)\n",
    "test_set.to_csv('test_set_preprocessed.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46a69eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
